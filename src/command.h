#pragma once

//! \file
//! \brief Command queue
//!
//! This code module implements the FIFO message queue that is used to to submit
//! commands from client threads that use `libudipe` via a \ref udipe_context_t
//! to a particuler worker thread managed by `libudipe`. Each worker thread gets
//! such a queue, and the \ref udipe_context_t takes care of balancing the
//! incoming workload between worker threads.

#include "arch.h"

#include <stdalign.h>
#include <stdatomic.h>
#include <threads.h>


/// Worker thread command queue capacity
///
/// This dictates how many commands can be waiting to be processed by the worker
/// thread before an attempt to enqueue another blocks the client thread,
/// thusly enforcing backpressure.
///
/// \internal
///
/// This capacity is chosen such that each command queue should fit inside of a
/// single dedicated page of data, by building upon the following principles:
///
/// - Any given client thread should send commands to `libudipe` rarely (and use
///   streams where chaining many commands is needed), so achieving spatial
///   cache locality across consecutive command submitted by the same client
///   thread in quick successions is not a goal.
/// - Each command may be submitted by a different client thread and should
///   therefore be written to its own false sharing granule.
/// - To maximize worker thread performance, the control block that multiple
///   client threads use to synchronize with each other, for which there may be
///   high cache contention, should be distinct from the control block that the
///   winner client thread uses to synchronize with the worker. We therefore
///   need two control blocks in addition to command storage.
/// - Because network transfers are much slower than integer division, we
///   probably do not need to enforce a power-of-two queue capacity (which, in
///   the presence of control blocks, would divides queue capacity by half).
#define COMMAND_QUEUE_LEN (LOWEST_PAGE_SIZE/FALSE_SHARING_GRANULARITY - 2)

/// Type of worker thread command
///
/// This enumeration covers the various command types that can be sent to a
/// worker thread, which largely match entry points from the udipe public API.
// TODO: Consider reusing these values for future type safety
typedef enum command_type_e {
    // TODO: Also plan ahead a "shut down now" signal, but it should ignore
    //       normal FIFO queuing. Maybe cross-thread SIGTERM could do?
    CONNECT = 1,  ///< Connect to a peer
    DISCONNECT,  ///< Disconnect from a peer
    SEND,  ///< Send a single UDP packet to a peer
    RECV,  ///< Receive a single UDP packet from a peer
    SEND_STREAM,  ///< Repeatedly send packets generated by a callback
    RECV_STREAM,  ///< Repeatedly receive packets and hand them to a callback
    INVALID = 0  ///< Placeholder, must be replaced by a valid command type
} command_type_t;

// TODO: Define individual command options: command_connect_t,
//       command_disconnect_t, etc.
//
//       To the docs of each of them, add the following.
//
//       \internal
//
//       This struct should be kept smaller than
//       `FALSE_SHARING_GRANULARITY - 12`, and ideally smaller than 52B for
//       optimal cache performance on x86 CPUs that only access one cache line
//        at a time.

/// Worker thread command
///
/// This is a complete worker thread command, which tells a worker thread about
/// a certain task that it should perform.
///
/// \internal
///
/// This struct should be kept smaller than \ref FALSE_SHARING_GRANULARITY, and
/// ideally smaller than 64B for optimal cache performance on x86 CPUs that only
/// access one cache line at a time.
struct command_s {
    // TODO: Define future_t in a different header, this will basically be a
    //       futex in a blob of size FALSE_SHARING_GRANULARITY within which
    //       additional data can be stored as needed. Value 0 indicates a result
    //       is not ready yet, positive value T indicate that a result of type T
    //       is available, and negative values indicate that an error occur.

    /// Completion future, to be filled up and signaled upon command completion
    ///
    /// If this is left at `NULL`, then the client is not interested in being
    /// notified when the command completes.
    alignas(FALSE_SHARING_GRANULARITY) future_t* completion;

    /// Parameters that are appropriate for this command type
    ///
    /// The value of \link #command_t::type `type`\endlink indicates which of
    /// this union's variants is valid.
    union {
        command_connect_t connect;  ///< \ref CONNECT parameters
        command_disconnect_t disconnect;  ///< \ref DISCONNECT parameters
        command_send_t send;  ///< \ref SEND parameters
        command_recv_t recv;  ///< \ref RECV parameters
        command_send_stream_t send_stream;  ///< \ref SEND_STREAM parameters
        command_recv_stream_t recv_stream;  ///< \ref RECV_STREAM parameters
    };

    /// Type of work that was requested from the worker thread
    ///
    /// This should not be set to `INVALID` in actual commands, the `INVALID`
    /// variant is only there to keep zero-initialization legal.
    command_type_t type;
};

/// Multi-producer single-consumer command queue of a `libudipe` worker thread
///
/// This queue is blocking on the client side but lock-free on the worker side,
/// following from the observation that UDP network threads are effectively soft
/// real-time tasks that require special lock-free care to minimize the odds of
/// packet loss, but other application threads (including the main thread) do
/// not normally require such precautions.
///
/// \internal
///
/// This struct is designed such that it fills up one small memory page (4KiB on
/// x86_64). The idea is that the command queue for each thread can be located
/// within one mmap()-allocated and mlock()ed block allocated by this thread.
//
// TODO: Figure out how the address of the command queue is passed back to the
//       main thread once this is done. Could just be a matter of filling up an
//       array in the udipe_context_t, decrementing an atomic each time, and
//       signaling a global futex once this is done.
typedef struct command_queue_s {
    // === First control block: Worker/Client synchronization ===

    /// Index within \link #command_queue_t::commands `commands`\endlink from
    /// which the worker thread will read next
    alignas(FALSE_SHARING_GRANULARITY) atomic_size_t worker_idx;

    /// Index within \link #command_queue_t::commands `commands`\endlink to
    /// which client threads will write next
    ///
    /// If this is equal to \link #command_queue_t::worker_idx
    /// `worker_idx`\endlink, then the queue is empty.
    atomic_size_t client_idx;

    /// Condition variable that client threads use to wait for the worker thread
    /// to process some commands
    ///
    /// Must be signaled with cond_signal() to avoid a thundering herd effect.
    cnd_t client_condition;

    // === Second control block: Client/Client synchronization ===

    /// Mutex that a client thread must lock to submit commands
    ///
    /// Should not be locked frequently as the intent is for commands to be rare
    /// (use streams for frequent commands), and uncontended mutexes are pretty
    /// cheap. But it is best to keep it on a separate cache line so that the
    /// worker thread is partially shielded from the cache ping pong that occurs
    /// when multiple clients are fighting for this mutex.
    alignas(FALSE_SHARING_GRANULARITY) mtx_t client_mutex;

    // === Next false sharing granules: Worker/Client synchronization ===

    /// Ring buffer that holds commands destined for worker thread processing
    ///
    /// The first control block indicates which entries from this array can be
    /// read by the worker thread, in which order they should be read, and where
    /// the client thread can safely write new entries.
    command_type_t commands[COMMAND_QUEUE_LEN];
} command_queue_t;

// TODO: Unit tests
